{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "ss = SparkSession.builder.getOrCreate()\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add S3 paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = ss.read.csv('mfcc_final.csv', header=True)\n",
    "cqt = ss.read.csv('/Users/RusL/Desktop/audio-project/cqt_final.csv', header=True)\n",
    "gender = ss.read.csv('Lab41-SRI-VOiCES-speaker-gender-dataset.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqt.cache()\n",
    "gender.cache()\n",
    "mfcc.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the cell below to drop useless columns\n",
    "\n",
    "For example, there might be 'Unnamed: 0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqt.columns # to see what columns are there\n",
    "cqt = cqt.drop(...)\n",
    "# Repeat this with mfcc and gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the filename and get the speaker id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a udf that extracts the speaker id out of the filename\n",
    "def get_speaker(filename):\n",
    "    i = filename.index('sp')\n",
    "    return int(filename[i+2:i+6])\n",
    "speaker = udf(get_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process speaker id\n",
    "cqt = cqt.withColumn('Speaker', speaker('FileName')).drop('FileName')\n",
    "mfcc = mfcc.withColumn('Speaker', speaker('FileName')).drop('FileName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join the tables and check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the dataframe\n",
    "results = gender.join(mfcc, on='Speaker', how='rightOuter')\\\n",
    "                .join(cqt, on='Speaker', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of observations\n",
    "print(results.count())\n",
    "print(cqt.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DistributedComputing",
   "language": "python",
   "name": "distributedcomputing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
